{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "import numpy as np\n",
    "\n",
    "gpu_on = True\n",
    "\n",
    "if gpu_on :\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n",
    "\n",
    "print(gpu_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num 8608 with 2 classes\n",
      "Total data num 1609 with 2 classes\n",
      "Total data num 1469 with 2 classes\n",
      "train_num: 8608\n",
      "valid_num: 1609\n",
      "test_num: 1469\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader.classification import ClassifyDataloader\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from glob import glob\n",
    "\n",
    "task = \"classification\"\n",
    "data_set_name = \"detect_lvi\"\n",
    "batch_size = 16\n",
    "on_memory = True\n",
    "target_size = (512,512)\n",
    "interpolation = \"bilinear\"\n",
    "class_mode = \"binary\"\n",
    "# class_mode = \"categorical\"\n",
    "dtype=\"float32\"\n",
    "\n",
    "\n",
    "train_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/train/*/*\")\n",
    "valid_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/valid/*/*\")\n",
    "test_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/test/*/*\")\n",
    "label_list = os.listdir(f\"./datasets/{task}/{data_set_name}/train\")\n",
    "\n",
    "label_to_index_dict = {label:index for index, label in enumerate(label_list)}\n",
    "index_to_label_dict = {index:label for index, label in enumerate(label_list)}\n",
    "\n",
    "train_data_loader = ClassifyDataloader(image_path_list=train_image_path_list,\n",
    "                                       label_to_index_dict=label_to_index_dict,\n",
    "                                       batch_size=batch_size,\n",
    "                                       on_memory=on_memory,\n",
    "                                       preprocess_input=preprocess_input,\n",
    "                                       target_size=target_size,\n",
    "                                       interpolation=interpolation,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=class_mode,\n",
    "                                       dtype=dtype\n",
    ")\n",
    "valid_data_loader = ClassifyDataloader(image_path_list=valid_image_path_list,\n",
    "                                       label_to_index_dict=label_to_index_dict,\n",
    "                                       batch_size=batch_size,\n",
    "                                       on_memory=False,\n",
    "                                       preprocess_input=preprocess_input,\n",
    "                                       target_size=target_size,\n",
    "                                       interpolation=interpolation,                                       \n",
    "                                       shuffle=False,\n",
    "                                       class_mode=class_mode,\n",
    "                                       dtype=dtype\n",
    ")\n",
    "test_data_loader = ClassifyDataloader(image_path_list=test_image_path_list,\n",
    "                                       label_to_index_dict=label_to_index_dict,\n",
    "                                       batch_size=batch_size,\n",
    "                                       on_memory=False,\n",
    "                                       preprocess_input=preprocess_input,\n",
    "                                       target_size=target_size,\n",
    "                                       interpolation=interpolation,                                      \n",
    "                                       shuffle=False,\n",
    "                                       class_mode=class_mode,\n",
    "                                       dtype=dtype\n",
    ")\n",
    "\n",
    "print(f\"train_num: {len(train_image_path_list)}\")\n",
    "print(f\"valid_num: {len(valid_image_path_list)}\")\n",
    "print(f\"test_num: {len(test_image_path_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "DROPOUT_RATIO = 0.5\n",
    "\n",
    "grad_cam = False\n",
    "transfer_learning = False\n",
    "epoch_release_frozen = 10\n",
    "transfer_train_mode = \"include_deep_layer\"\n",
    "layer_name_frozen_to = \"mixed4\"\n",
    "\n",
    "#  binary_sigmoid, categorical_sigmoid, categorical_softmax\n",
    "activation = \"binary_sigmoid\"\n",
    "\n",
    "# create the base pre-trained model~\n",
    "base_model = InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(None,None,3),\n",
    "    classes=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=None\n",
    ")\n",
    "\n",
    "if transfer_learning:\n",
    "    if train_mode == \"dense_only\":\n",
    "        base_model.trainable = False\n",
    "    elif train_mode == \"include_deep_layer\":\n",
    "        for layer in base_model.layers: \n",
    "            layer.trainable = False\n",
    "            if layer.name == layer_name_frozen_to:\n",
    "                break\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "# (Batch_Size,?)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(DROPOUT_RATIO)(x)\n",
    "# let's add a fully-connected layer\n",
    "# (Batch_Size,1)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# (Batch_Size,1024)\n",
    "x = Dropout(DROPOUT_RATIO)(x)\n",
    "\n",
    "if grad_cam:\n",
    "    x *= 1e-1\n",
    "    keras_backend.set_floatx('float64')\n",
    "    dense_dtype = \"float64\"\n",
    "else:\n",
    "    dense_dtype = \"float32\"\n",
    "    \n",
    "if activation == \"binary_sigmoid\":\n",
    "    predictions = Dense(1, activation='sigmoid', dtype=dense_dtype)(x)\n",
    "    loss_function = BinaryCrossentropy(label_smoothing=0.01)\n",
    "elif activation == \"categorical_sigmoid\":\n",
    "    predictions = Dense(2, activation='sigmoid', dtype=dense_dtype)(x)\n",
    "    loss_function = CategoricalCrossentropy(label_smoothing=0.01)\n",
    "elif activation == \"categorical_softmax\":\n",
    "    predictions = Dense(2, activation='softmax', dtype=dense_dtype)(x)\n",
    "    loss_function = CategoricalCrossentropy(label_smoothing=0.01)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# YY/MM/dd\n",
    "today_str = today.strftime(\"%Y/%m/%d\")\n",
    "today_weight_path = f\"./weights/{task}/{data_set_name}/{today_str}/\" \n",
    "today_logs_path = f\"./logs/{task}/{data_set_name}/{today_str}/\"\n",
    "os.makedirs(today_weight_path, exist_ok=True)\n",
    "os.makedirs(today_logs_path, exist_ok=True)\n",
    "optimizer = Nadam(1e-3, clipnorm=1)\n",
    "\n",
    "save_c = ModelCheckpoint(\n",
    "    today_weight_path+\"/weights_{epoch:02d}_{loss:.4f}.hdf5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min')\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=5,\n",
    "    min_lr=1e-9)\n",
    "csv_logger = CSVLogger(f'{today_logs_path}/log.csv', append=False, separator=',')\n",
    "\n",
    "\n",
    "def make_model_trainable(epoch, model, target_epoch):\n",
    "    if epoch > target_epoch:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "make_trainable_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: make_model_trainable(epoch, model, target_epoch=epoch_release_frozen)\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "538/538 [==============================] - 393s 694ms/step - loss: 0.7139 - accuracy: 0.5688 - val_loss: 5.3206 - val_accuracy: 0.5606\n",
      "Epoch 2/200\n",
      "538/538 [==============================] - 326s 605ms/step - loss: 0.6441 - accuracy: 0.6360 - val_loss: 5.0576 - val_accuracy: 0.5450\n",
      "Epoch 3/200\n",
      "538/538 [==============================] - 325s 605ms/step - loss: 0.5694 - accuracy: 0.7169 - val_loss: 0.5794 - val_accuracy: 0.6938\n",
      "Epoch 4/200\n",
      "538/538 [==============================] - 325s 604ms/step - loss: 0.5538 - accuracy: 0.7272 - val_loss: 13.8843 - val_accuracy: 0.5669\n",
      "Epoch 5/200\n",
      "538/538 [==============================] - 324s 603ms/step - loss: 0.5134 - accuracy: 0.7548 - val_loss: 38.5504 - val_accuracy: 0.4919\n",
      "Epoch 6/200\n",
      "538/538 [==============================] - 324s 602ms/step - loss: 0.4905 - accuracy: 0.7685 - val_loss: 1.0924 - val_accuracy: 0.5944\n",
      "Epoch 7/200\n",
      "538/538 [==============================] - 326s 605ms/step - loss: 0.4020 - accuracy: 0.8223 - val_loss: 0.8415 - val_accuracy: 0.6694\n",
      "Epoch 8/200\n",
      "538/538 [==============================] - 326s 606ms/step - loss: 0.3583 - accuracy: 0.8527 - val_loss: 0.5707 - val_accuracy: 0.8012\n",
      "Epoch 9/200\n",
      "538/538 [==============================] - 324s 602ms/step - loss: 0.3111 - accuracy: 0.8783 - val_loss: 1.0578 - val_accuracy: 0.6894\n",
      "Epoch 10/200\n",
      "538/538 [==============================] - 326s 605ms/step - loss: 0.2789 - accuracy: 0.8951 - val_loss: 0.4193 - val_accuracy: 0.8462\n",
      "Epoch 11/200\n",
      "538/538 [==============================] - 325s 603ms/step - loss: 0.2578 - accuracy: 0.9051 - val_loss: 0.9858 - val_accuracy: 0.7237\n",
      "Epoch 12/200\n",
      "538/538 [==============================] - 325s 603ms/step - loss: 0.2336 - accuracy: 0.9205 - val_loss: 0.4504 - val_accuracy: 0.8519\n",
      "Epoch 13/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.2078 - accuracy: 0.9270 - val_loss: 0.6118 - val_accuracy: 0.8206\n",
      "Epoch 14/200\n",
      "538/538 [==============================] - 323s 601ms/step - loss: 0.1976 - accuracy: 0.9381 - val_loss: 0.2867 - val_accuracy: 0.9094\n",
      "Epoch 15/200\n",
      "538/538 [==============================] - 324s 603ms/step - loss: 0.1733 - accuracy: 0.9462 - val_loss: 1.4687 - val_accuracy: 0.7237\n",
      "Epoch 16/200\n",
      "538/538 [==============================] - 325s 603ms/step - loss: 0.1599 - accuracy: 0.9531 - val_loss: 0.5627 - val_accuracy: 0.7994\n",
      "Epoch 17/200\n",
      "538/538 [==============================] - 323s 601ms/step - loss: 0.1401 - accuracy: 0.9554 - val_loss: 0.4672 - val_accuracy: 0.8550\n",
      "Epoch 18/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.1324 - accuracy: 0.9618 - val_loss: 1.5655 - val_accuracy: 0.6363\n",
      "Epoch 19/200\n",
      "538/538 [==============================] - 322s 597ms/step - loss: 0.1276 - accuracy: 0.9650 - val_loss: 0.9397 - val_accuracy: 0.8188\n",
      "Epoch 20/200\n",
      "538/538 [==============================] - 321s 598ms/step - loss: 0.1141 - accuracy: 0.9684 - val_loss: 0.5344 - val_accuracy: 0.8175\n",
      "Epoch 21/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.1098 - accuracy: 0.9708 - val_loss: 0.9119 - val_accuracy: 0.7650\n",
      "Epoch 22/200\n",
      "538/538 [==============================] - 319s 594ms/step - loss: 0.1019 - accuracy: 0.9736 - val_loss: 0.7686 - val_accuracy: 0.8419\n",
      "Epoch 23/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0876 - accuracy: 0.9797 - val_loss: 0.5027 - val_accuracy: 0.8444\n",
      "Epoch 24/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0892 - accuracy: 0.9798 - val_loss: 1.2699 - val_accuracy: 0.7094\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 25/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0569 - accuracy: 0.9914 - val_loss: 0.3758 - val_accuracy: 0.8944\n",
      "Epoch 26/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0507 - accuracy: 0.9941 - val_loss: 0.3649 - val_accuracy: 0.8969\n",
      "Epoch 27/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0434 - accuracy: 0.9965 - val_loss: 0.4185 - val_accuracy: 0.8856\n",
      "Epoch 28/200\n",
      "538/538 [==============================] - 319s 593ms/step - loss: 0.0478 - accuracy: 0.9955 - val_loss: 0.3772 - val_accuracy: 0.8944\n",
      "Epoch 29/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0417 - accuracy: 0.9977 - val_loss: 0.4188 - val_accuracy: 0.8906\n",
      "Epoch 30/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0409 - accuracy: 0.9976 - val_loss: 0.4574 - val_accuracy: 0.8831\n",
      "Epoch 31/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0406 - accuracy: 0.9980 - val_loss: 0.3472 - val_accuracy: 0.9069\n",
      "Epoch 32/200\n",
      "538/538 [==============================] - 319s 594ms/step - loss: 0.0401 - accuracy: 0.9981 - val_loss: 0.3948 - val_accuracy: 0.8988\n",
      "Epoch 33/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0406 - accuracy: 0.9977 - val_loss: 0.4342 - val_accuracy: 0.8919\n",
      "Epoch 34/200\n",
      "538/538 [==============================] - 319s 594ms/step - loss: 0.0393 - accuracy: 0.9983 - val_loss: 0.3873 - val_accuracy: 0.9006\n",
      "Epoch 35/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0374 - accuracy: 0.9986 - val_loss: 0.4961 - val_accuracy: 0.8750\n",
      "Epoch 36/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0414 - accuracy: 0.9974 - val_loss: 0.3696 - val_accuracy: 0.9106\n",
      "Epoch 37/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0427 - accuracy: 0.9972 - val_loss: 0.5883 - val_accuracy: 0.8525\n",
      "Epoch 38/200\n",
      "538/538 [==============================] - 319s 594ms/step - loss: 0.0372 - accuracy: 0.9993 - val_loss: 0.4705 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 39/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0360 - accuracy: 0.9994 - val_loss: 0.4450 - val_accuracy: 0.8931\n",
      "Epoch 40/200\n",
      "538/538 [==============================] - 319s 593ms/step - loss: 0.0466 - accuracy: 0.9970 - val_loss: 0.4342 - val_accuracy: 0.8969\n",
      "Epoch 41/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0350 - accuracy: 0.9997 - val_loss: 0.4266 - val_accuracy: 0.8981\n",
      "Epoch 42/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0374 - accuracy: 0.9990 - val_loss: 0.4361 - val_accuracy: 0.8944\n",
      "Epoch 43/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0354 - accuracy: 0.9995 - val_loss: 0.4331 - val_accuracy: 0.8969\n",
      "Epoch 44/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0357 - accuracy: 0.9995 - val_loss: 0.4331 - val_accuracy: 0.8975\n",
      "Epoch 45/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0359 - accuracy: 0.9993 - val_loss: 0.4248 - val_accuracy: 0.8988\n",
      "Epoch 46/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0369 - accuracy: 0.9990 - val_loss: 0.4274 - val_accuracy: 0.8963\n",
      "Epoch 47/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0375 - accuracy: 0.9986 - val_loss: 0.4377 - val_accuracy: 0.8931\n",
      "Epoch 48/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0357 - accuracy: 0.9994 - val_loss: 0.4530 - val_accuracy: 0.8900\n",
      "Epoch 49/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0355 - accuracy: 0.9992 - val_loss: 0.4232 - val_accuracy: 0.8956\n",
      "Epoch 50/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0345 - accuracy: 0.9999 - val_loss: 0.4300 - val_accuracy: 0.8944\n",
      "Epoch 51/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0398 - accuracy: 0.9984 - val_loss: 0.4447 - val_accuracy: 0.8900\n",
      "Epoch 52/200\n",
      "538/538 [==============================] - 323s 601ms/step - loss: 0.0355 - accuracy: 0.9995 - val_loss: 0.4330 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 53/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0359 - accuracy: 0.9993 - val_loss: 0.4335 - val_accuracy: 0.8919\n",
      "Epoch 54/200\n",
      "538/538 [==============================] - 320s 596ms/step - loss: 0.0363 - accuracy: 0.9993 - val_loss: 0.4401 - val_accuracy: 0.8925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0357 - accuracy: 0.9994 - val_loss: 0.4431 - val_accuracy: 0.8913\n",
      "Epoch 56/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0353 - accuracy: 0.9997 - val_loss: 0.4255 - val_accuracy: 0.8981\n",
      "Epoch 57/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0359 - accuracy: 0.9997 - val_loss: 0.4421 - val_accuracy: 0.8913\n",
      "Epoch 58/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0347 - accuracy: 0.9997 - val_loss: 0.4299 - val_accuracy: 0.8950\n",
      "Epoch 59/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0365 - accuracy: 0.9991 - val_loss: 0.4246 - val_accuracy: 0.8975\n",
      "Epoch 60/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0347 - accuracy: 0.9997 - val_loss: 0.4289 - val_accuracy: 0.8950\n",
      "Epoch 61/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0366 - accuracy: 0.9992 - val_loss: 0.4282 - val_accuracy: 0.8975\n",
      "Epoch 62/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0347 - accuracy: 0.9995 - val_loss: 0.4234 - val_accuracy: 0.8981\n",
      "Epoch 63/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0345 - accuracy: 0.9998 - val_loss: 0.4267 - val_accuracy: 0.8969\n",
      "Epoch 64/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0350 - accuracy: 0.9997 - val_loss: 0.4266 - val_accuracy: 0.8975\n",
      "Epoch 65/200\n",
      "538/538 [==============================] - 319s 593ms/step - loss: 0.0398 - accuracy: 0.9985 - val_loss: 0.4366 - val_accuracy: 0.8931\n",
      "Epoch 66/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0351 - accuracy: 0.9995 - val_loss: 0.4322 - val_accuracy: 0.8938\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 67/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0351 - accuracy: 0.9997 - val_loss: 0.4286 - val_accuracy: 0.8944\n",
      "Epoch 68/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0360 - accuracy: 0.9992 - val_loss: 0.4308 - val_accuracy: 0.8956\n",
      "Epoch 69/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0347 - accuracy: 0.9997 - val_loss: 0.4348 - val_accuracy: 0.8944\n",
      "Epoch 70/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0348 - accuracy: 0.9997 - val_loss: 0.4228 - val_accuracy: 0.8988\n",
      "Epoch 71/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0360 - accuracy: 0.9991 - val_loss: 0.4376 - val_accuracy: 0.8950\n",
      "Epoch 72/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0382 - accuracy: 0.9987 - val_loss: 0.4369 - val_accuracy: 0.8931\n",
      "Epoch 73/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0350 - accuracy: 0.9998 - val_loss: 0.4347 - val_accuracy: 0.8963\n",
      "Epoch 74/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0348 - accuracy: 0.9999 - val_loss: 0.4284 - val_accuracy: 0.8969\n",
      "Epoch 75/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0351 - accuracy: 0.9994 - val_loss: 0.4260 - val_accuracy: 0.8963\n",
      "Epoch 76/200\n",
      "538/538 [==============================] - 320s 596ms/step - loss: 0.0356 - accuracy: 0.9995 - val_loss: 0.4339 - val_accuracy: 0.8931\n",
      "Epoch 77/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0367 - accuracy: 0.9990 - val_loss: 0.4356 - val_accuracy: 0.8931\n",
      "Epoch 78/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0350 - accuracy: 0.9997 - val_loss: 0.4375 - val_accuracy: 0.8919\n",
      "Epoch 79/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0354 - accuracy: 0.9994 - val_loss: 0.4285 - val_accuracy: 0.8975\n",
      "Epoch 80/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0400 - accuracy: 0.9984 - val_loss: 0.4287 - val_accuracy: 0.8938\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 81/200\n",
      "538/538 [==============================] - 320s 596ms/step - loss: 0.0357 - accuracy: 0.9993 - val_loss: 0.4249 - val_accuracy: 0.8988\n",
      "Epoch 82/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0356 - accuracy: 0.9993 - val_loss: 0.4360 - val_accuracy: 0.8938\n",
      "Epoch 83/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0349 - accuracy: 0.9995 - val_loss: 0.4425 - val_accuracy: 0.8925\n",
      "Epoch 84/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0357 - accuracy: 0.9993 - val_loss: 0.4352 - val_accuracy: 0.8925\n",
      "Epoch 85/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0385 - accuracy: 0.9986 - val_loss: 0.4345 - val_accuracy: 0.8938\n",
      "Epoch 86/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0364 - accuracy: 0.9988 - val_loss: 0.4392 - val_accuracy: 0.8919\n",
      "Epoch 87/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0391 - accuracy: 0.9986 - val_loss: 0.4369 - val_accuracy: 0.8944\n",
      "Epoch 88/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0385 - accuracy: 0.9987 - val_loss: 0.4313 - val_accuracy: 0.8963\n",
      "Epoch 89/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0349 - accuracy: 0.9994 - val_loss: 0.4414 - val_accuracy: 0.8925\n",
      "Epoch 90/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0346 - accuracy: 0.9998 - val_loss: 0.4297 - val_accuracy: 0.8988\n",
      "Epoch 91/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0348 - accuracy: 0.9994 - val_loss: 0.4329 - val_accuracy: 0.8956\n",
      "Epoch 92/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0352 - accuracy: 0.9998 - val_loss: 0.4349 - val_accuracy: 0.8950\n",
      "Epoch 93/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0349 - accuracy: 0.9998 - val_loss: 0.4274 - val_accuracy: 0.8975\n",
      "Epoch 94/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0353 - accuracy: 0.9995 - val_loss: 0.4292 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 95/200\n",
      "538/538 [==============================] - 320s 593ms/step - loss: 0.0359 - accuracy: 0.9993 - val_loss: 0.4243 - val_accuracy: 0.8988\n",
      "Epoch 96/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0351 - accuracy: 0.9997 - val_loss: 0.4394 - val_accuracy: 0.8931\n",
      "Epoch 97/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0354 - accuracy: 0.9993 - val_loss: 0.4316 - val_accuracy: 0.8956\n",
      "Epoch 98/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0354 - accuracy: 0.9998 - val_loss: 0.4339 - val_accuracy: 0.8944\n",
      "Epoch 99/200\n",
      "538/538 [==============================] - 319s 593ms/step - loss: 0.0350 - accuracy: 0.9995 - val_loss: 0.4350 - val_accuracy: 0.8919\n",
      "Epoch 100/200\n",
      "538/538 [==============================] - 319s 593ms/step - loss: 0.0355 - accuracy: 0.9994 - val_loss: 0.4405 - val_accuracy: 0.8925\n",
      "Epoch 101/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0357 - accuracy: 0.9991 - val_loss: 0.4361 - val_accuracy: 0.8931\n",
      "Epoch 102/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0408 - accuracy: 0.9981 - val_loss: 0.4388 - val_accuracy: 0.8925\n",
      "Epoch 103/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0353 - accuracy: 0.9995 - val_loss: 0.4370 - val_accuracy: 0.8938\n",
      "Epoch 104/200\n",
      "538/538 [==============================] - 320s 594ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8950\n",
      "Epoch 105/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0352 - accuracy: 0.9995 - val_loss: 0.4287 - val_accuracy: 0.8944\n",
      "Epoch 106/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0350 - accuracy: 0.9997 - val_loss: 0.4330 - val_accuracy: 0.8956\n",
      "Epoch 107/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0346 - accuracy: 0.9998 - val_loss: 0.4283 - val_accuracy: 0.8950\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0348 - accuracy: 0.9994 - val_loss: 0.4277 - val_accuracy: 0.8975\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1e-09.\n",
      "Epoch 109/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0351 - accuracy: 0.9999 - val_loss: 0.4347 - val_accuracy: 0.8950\n",
      "Epoch 110/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0350 - accuracy: 0.9997 - val_loss: 0.4331 - val_accuracy: 0.8944\n",
      "Epoch 111/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0358 - accuracy: 0.9993 - val_loss: 0.4275 - val_accuracy: 0.8963\n",
      "Epoch 112/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0350 - accuracy: 0.9995 - val_loss: 0.4308 - val_accuracy: 0.8956\n",
      "Epoch 113/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0354 - accuracy: 0.9995 - val_loss: 0.4300 - val_accuracy: 0.8963\n",
      "Epoch 114/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0348 - accuracy: 0.9998 - val_loss: 0.4236 - val_accuracy: 0.8994\n",
      "Epoch 115/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0403 - accuracy: 0.9986 - val_loss: 0.4432 - val_accuracy: 0.8919\n",
      "Epoch 116/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0349 - accuracy: 0.9998 - val_loss: 0.4296 - val_accuracy: 0.8963\n",
      "Epoch 117/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0425 - accuracy: 0.9983 - val_loss: 0.4288 - val_accuracy: 0.8938\n",
      "Epoch 118/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0356 - accuracy: 0.9993 - val_loss: 0.4374 - val_accuracy: 0.8944\n",
      "Epoch 119/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0345 - accuracy: 0.9998 - val_loss: 0.4388 - val_accuracy: 0.8938\n",
      "Epoch 120/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0351 - accuracy: 0.9995 - val_loss: 0.4349 - val_accuracy: 0.8931\n",
      "Epoch 121/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0352 - accuracy: 0.9997 - val_loss: 0.4386 - val_accuracy: 0.8938\n",
      "Epoch 122/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0350 - accuracy: 0.9994 - val_loss: 0.4191 - val_accuracy: 0.9000\n",
      "Epoch 123/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0351 - accuracy: 0.9994 - val_loss: 0.4326 - val_accuracy: 0.8950\n",
      "Epoch 124/200\n",
      "538/538 [==============================] - 321s 597ms/step - loss: 0.0354 - accuracy: 0.9994 - val_loss: 0.4313 - val_accuracy: 0.8944\n",
      "Epoch 125/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0347 - accuracy: 0.9998 - val_loss: 0.4366 - val_accuracy: 0.8938\n",
      "Epoch 126/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0354 - accuracy: 0.9995 - val_loss: 0.4396 - val_accuracy: 0.8938\n",
      "Epoch 127/200\n",
      "538/538 [==============================] - 320s 595ms/step - loss: 0.0356 - accuracy: 0.9994 - val_loss: 0.4339 - val_accuracy: 0.8975\n",
      "Epoch 128/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0356 - accuracy: 0.9993 - val_loss: 0.4292 - val_accuracy: 0.8956\n",
      "Epoch 129/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0356 - accuracy: 0.9995 - val_loss: 0.4315 - val_accuracy: 0.8956\n",
      "Epoch 130/200\n",
      "538/538 [==============================] - 322s 598ms/step - loss: 0.0351 - accuracy: 0.9997 - val_loss: 0.4360 - val_accuracy: 0.8944\n",
      "Epoch 131/200\n",
      "538/538 [==============================] - 319s 594ms/step - loss: 0.0364 - accuracy: 0.9993 - val_loss: 0.4264 - val_accuracy: 0.8975\n",
      "Epoch 132/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0364 - accuracy: 0.9992 - val_loss: 0.4297 - val_accuracy: 0.8975\n",
      "Epoch 133/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8950\n",
      "Epoch 134/200\n",
      "538/538 [==============================] - 371s 690ms/step - loss: 0.0352 - accuracy: 0.9997 - val_loss: 0.4313 - val_accuracy: 0.8950\n",
      "Epoch 135/200\n",
      "538/538 [==============================] - 336s 624ms/step - loss: 0.0346 - accuracy: 0.9998 - val_loss: 0.4324 - val_accuracy: 0.8950\n",
      "Epoch 136/200\n",
      "538/538 [==============================] - 406s 755ms/step - loss: 0.0394 - accuracy: 0.9990 - val_loss: 0.4347 - val_accuracy: 0.8938\n",
      "Epoch 137/200\n",
      "538/538 [==============================] - 452s 840ms/step - loss: 0.0349 - accuracy: 0.9997 - val_loss: 0.4296 - val_accuracy: 0.8956\n",
      "Epoch 138/200\n",
      "538/538 [==============================] - 360s 670ms/step - loss: 0.0381 - accuracy: 0.9988 - val_loss: 0.4369 - val_accuracy: 0.8925\n",
      "Epoch 139/200\n",
      "538/538 [==============================] - 387s 720ms/step - loss: 0.0358 - accuracy: 0.9994 - val_loss: 0.4322 - val_accuracy: 0.8950\n",
      "Epoch 140/200\n",
      "538/538 [==============================] - 356s 661ms/step - loss: 0.0353 - accuracy: 0.9994 - val_loss: 0.4261 - val_accuracy: 0.8969\n",
      "Epoch 141/200\n",
      "538/538 [==============================] - 326s 606ms/step - loss: 0.0357 - accuracy: 0.9994 - val_loss: 0.4377 - val_accuracy: 0.8919\n",
      "Epoch 142/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0347 - accuracy: 0.9997 - val_loss: 0.4385 - val_accuracy: 0.8931\n",
      "Epoch 143/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0361 - accuracy: 0.9993 - val_loss: 0.4356 - val_accuracy: 0.8931\n",
      "Epoch 144/200\n",
      "538/538 [==============================] - 321s 596ms/step - loss: 0.0345 - accuracy: 0.9999 - val_loss: 0.4255 - val_accuracy: 0.8975\n",
      "Epoch 145/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0351 - accuracy: 0.9995 - val_loss: 0.4352 - val_accuracy: 0.8944\n",
      "Epoch 146/200\n",
      "538/538 [==============================] - 326s 605ms/step - loss: 0.0348 - accuracy: 0.9995 - val_loss: 0.4458 - val_accuracy: 0.8925\n",
      "Epoch 147/200\n",
      "538/538 [==============================] - 322s 599ms/step - loss: 0.0363 - accuracy: 0.9992 - val_loss: 0.4395 - val_accuracy: 0.8913\n",
      "Epoch 148/200\n",
      "538/538 [==============================] - 323s 600ms/step - loss: 0.0357 - accuracy: 0.9997 - val_loss: 0.4293 - val_accuracy: 0.8950\n",
      "Epoch 149/200\n",
      "233/538 [===========>..................] - ETA: 2:28 - loss: 0.0349 - accuracy: 0.9997"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 200\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduceLROnPlat, save_c, csv_logger, make_trainable_callback],\n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
