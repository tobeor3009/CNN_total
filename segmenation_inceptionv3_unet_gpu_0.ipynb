{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "import segmentation_models as sm\n",
    "\n",
    "from src.data_loader.segmentation import SegDataloader\n",
    "\n",
    "sm.set_framework ('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpu_on = True\n",
    "\n",
    "if gpu_on :\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "print(gpu_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data num 4600\n",
      "Total data num 415\n",
      "Total data num 1111\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader.segmentation import SegDataloader\n",
    "from glob import glob\n",
    "\n",
    "BACKBONE=\"inceptionv3\"\n",
    "\n",
    "task = \"segmentation\"\n",
    "data_set_name = \"glomerulus_0.65_1024_remove_peel_split_man\"\n",
    "batch_size = 8\n",
    "on_memory = False\n",
    "argumentation_proba = 0.8\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "target_size = (512,512)\n",
    "interpolation = \"bilinear\"\n",
    "dtype = \"float32\"\n",
    "\n",
    "\n",
    "train_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/train/image/*\")\n",
    "train_mask_path_list = glob(f\"./datasets/{task}/{data_set_name}/train/mask/*\")\n",
    "\n",
    "valid_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/valid/image/*\")\n",
    "valid_mask_path_list = glob(f\"./datasets/{task}/{data_set_name}/valid/mask/*\")\n",
    "\n",
    "test_image_path_list = glob(f\"./datasets/{task}/{data_set_name}/test/image/*\")\n",
    "test_mask_path_list = glob(f\"./datasets/{task}/{data_set_name}/test/mask/*\")\n",
    "\n",
    "train_data_loader = SegDataloader(image_path_list=train_image_path_list,\n",
    "                                  mask_path_list=train_mask_path_list,\n",
    "                                  batch_size=batch_size,\n",
    "                                  on_memory=on_memory,\n",
    "                                  argumentation_proba=0.8,\n",
    "                                  preprocess_input=preprocess_input,\n",
    "                                  target_size=target_size,\n",
    "                                  interpolation=interpolation,\n",
    "                                  shuffle=True,\n",
    "                                  dtype=dtype\n",
    "                                  )\n",
    "valid_data_loader = SegDataloader(image_path_list=valid_image_path_list,\n",
    "                                  mask_path_list=valid_mask_path_list,\n",
    "                                  batch_size=batch_size,\n",
    "                                  on_memory=on_memory,\n",
    "                                  argumentation_proba=0,\n",
    "                                  preprocess_input=preprocess_input,\n",
    "                                  target_size=target_size,\n",
    "                                  interpolation=interpolation,\n",
    "                                  shuffle=True,\n",
    "                                  dtype=dtype\n",
    "                                  )\n",
    "test_data_loader = SegDataloader(image_path_list=test_image_path_list,\n",
    "                                 mask_path_list=test_mask_path_list,\n",
    "                                 batch_size=batch_size,\n",
    "                                 on_memory=False,\n",
    "                                 argumentation_proba=0,\n",
    "                                 preprocess_input=preprocess_input,\n",
    "                                 target_size=target_size,\n",
    "                                 interpolation=interpolation,\n",
    "                                 shuffle=False,\n",
    "                                 dtype=dtype\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "epoch_release_frozen =10\n",
    "\n",
    "# create the base pre-trained model~\n",
    "model = sm.Unet(backbone_name=BACKBONE, input_shape=(\n",
    "            None, None, 3), classes=1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "from src.util.custom_loss import WeightedRegionLoss, TverskyLoss, dice_score, dice_loss\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# YY/MM/dd\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "today_weight_path = f\"./weights/{task}/{data_set_name}/{today_str}/target_size_{target_size}/\" \n",
    "today_logs_path = f\"./logs/{task}/{data_set_name}/{today_str}/target_size_{target_size}/\"\n",
    "os.makedirs(today_weight_path, exist_ok=True)\n",
    "os.makedirs(today_logs_path, exist_ok=True)\n",
    "optimizer = Nadam(1e-5, clipnorm=1)\n",
    "\n",
    "save_c = ModelCheckpoint(\n",
    "    today_weight_path+\"/weights_{val_loss:.4f}_{loss:.4f}_{epoch:02d}.hdf5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min')\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=5,\n",
    "    min_lr=1e-7)\n",
    "csv_logger = CSVLogger(f'{today_logs_path}/log.csv', append=False, separator=',')\n",
    "\n",
    "\n",
    "def make_model_trainable(epoch, model, target_epoch):\n",
    "    if epoch > target_epoch:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "make_trainable_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: make_model_trainable(epoch, model, target_epoch=epoch_release_frozen)\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=WeightedRegionLoss(), metrics=[dice_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "575/575 [==============================] - 329s 513ms/step - loss: 0.1357 - dice_score: 0.2425 - val_loss: 0.1048 - val_dice_score: 0.3177\n",
      "Epoch 2/200\n",
      "575/575 [==============================] - 282s 490ms/step - loss: 0.0850 - dice_score: 0.3741 - val_loss: 0.0674 - val_dice_score: 0.5942\n",
      "Epoch 3/200\n",
      "575/575 [==============================] - 282s 490ms/step - loss: 0.0600 - dice_score: 0.7415 - val_loss: 0.0502 - val_dice_score: 0.8564\n",
      "Epoch 4/200\n",
      "575/575 [==============================] - 281s 487ms/step - loss: 0.0458 - dice_score: 0.8596 - val_loss: 0.0388 - val_dice_score: 0.8939\n",
      "Epoch 5/200\n",
      "575/575 [==============================] - 280s 487ms/step - loss: 0.0360 - dice_score: 0.8852 - val_loss: 0.0322 - val_dice_score: 0.9269\n",
      "Epoch 6/200\n",
      "575/575 [==============================] - 281s 489ms/step - loss: 0.0289 - dice_score: 0.9031 - val_loss: 0.0255 - val_dice_score: 0.9191\n",
      "Epoch 7/200\n",
      "575/575 [==============================] - 280s 487ms/step - loss: 0.0237 - dice_score: 0.9010 - val_loss: 0.0213 - val_dice_score: 0.9242\n",
      "Epoch 8/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0194 - dice_score: 0.9168 - val_loss: 0.0182 - val_dice_score: 0.9277\n",
      "Epoch 9/200\n",
      "575/575 [==============================] - 280s 487ms/step - loss: 0.0161 - dice_score: 0.9187 - val_loss: 0.0149 - val_dice_score: 0.9324\n",
      "Epoch 10/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0136 - dice_score: 0.9247 - val_loss: 0.0127 - val_dice_score: 0.9316\n",
      "Epoch 11/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0115 - dice_score: 0.9307 - val_loss: 0.0109 - val_dice_score: 0.9329\n",
      "Epoch 12/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0100 - dice_score: 0.9202 - val_loss: 0.0094 - val_dice_score: 0.9355\n",
      "Epoch 13/200\n",
      "575/575 [==============================] - 279s 486ms/step - loss: 0.0086 - dice_score: 0.9353 - val_loss: 0.0086 - val_dice_score: 0.9375\n",
      "Epoch 14/200\n",
      "575/575 [==============================] - 278s 483ms/step - loss: 0.0076 - dice_score: 0.9324 - val_loss: 0.0078 - val_dice_score: 0.9216\n",
      "Epoch 15/200\n",
      "575/575 [==============================] - 278s 484ms/step - loss: 0.0066 - dice_score: 0.9421 - val_loss: 0.0069 - val_dice_score: 0.9419\n",
      "Epoch 16/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0059 - dice_score: 0.9412 - val_loss: 0.0065 - val_dice_score: 0.9362\n",
      "Epoch 17/200\n",
      "575/575 [==============================] - 279s 484ms/step - loss: 0.0054 - dice_score: 0.9391 - val_loss: 0.0059 - val_dice_score: 0.9203\n",
      "Epoch 18/200\n",
      "575/575 [==============================] - 278s 484ms/step - loss: 0.0049 - dice_score: 0.9312 - val_loss: 0.0056 - val_dice_score: 0.9341\n",
      "Epoch 19/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0045 - dice_score: 0.9475 - val_loss: 0.0053 - val_dice_score: 0.9359\n",
      "Epoch 20/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0042 - dice_score: 0.9501 - val_loss: 0.0052 - val_dice_score: 0.9381\n",
      "Epoch 21/200\n",
      "575/575 [==============================] - 278s 483ms/step - loss: 0.0040 - dice_score: 0.9435 - val_loss: 0.0046 - val_dice_score: 0.9241\n",
      "Epoch 22/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0038 - dice_score: 0.9493 - val_loss: 0.0047 - val_dice_score: 0.9365\n",
      "Epoch 23/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0037 - dice_score: 0.9468 - val_loss: 0.0045 - val_dice_score: 0.9369\n",
      "Epoch 24/200\n",
      "575/575 [==============================] - 278s 483ms/step - loss: 0.0035 - dice_score: 0.9511 - val_loss: 0.0044 - val_dice_score: 0.9450\n",
      "Epoch 25/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0034 - dice_score: 0.9548 - val_loss: 0.0041 - val_dice_score: 0.9387\n",
      "Epoch 26/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0032 - dice_score: 0.9531 - val_loss: 0.0041 - val_dice_score: 0.9456\n",
      "Epoch 27/200\n",
      "575/575 [==============================] - 279s 484ms/step - loss: 0.0033 - dice_score: 0.9566 - val_loss: 0.0045 - val_dice_score: 0.9369\n",
      "Epoch 28/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0032 - dice_score: 0.9559 - val_loss: 0.0042 - val_dice_score: 0.9428\n",
      "Epoch 29/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0031 - dice_score: 0.9576 - val_loss: 0.0041 - val_dice_score: 0.9419\n",
      "Epoch 30/200\n",
      "575/575 [==============================] - 279s 484ms/step - loss: 0.0031 - dice_score: 0.9574 - val_loss: 0.0043 - val_dice_score: 0.9293\n",
      "Epoch 31/200\n",
      "575/575 [==============================] - 280s 486ms/step - loss: 0.0030 - dice_score: 0.9590 - val_loss: 0.0040 - val_dice_score: 0.9415\n",
      "Epoch 32/200\n",
      "575/575 [==============================] - 280s 487ms/step - loss: 0.0029 - dice_score: 0.9607 - val_loss: 0.0040 - val_dice_score: 0.9445\n",
      "Epoch 33/200\n",
      "575/575 [==============================] - 279s 485ms/step - loss: 0.0029 - dice_score: 0.9543 - val_loss: 0.0041 - val_dice_score: 0.9345\n",
      "Epoch 34/200\n",
      "575/575 [==============================] - 285s 495ms/step - loss: 0.0029 - dice_score: 0.9554 - val_loss: 0.0039 - val_dice_score: 0.9284\n",
      "Epoch 35/200\n",
      "575/575 [==============================] - 306s 531ms/step - loss: 0.0028 - dice_score: 0.9651 - val_loss: 0.0039 - val_dice_score: 0.9449\n",
      "Epoch 36/200\n",
      "575/575 [==============================] - 307s 533ms/step - loss: 0.0028 - dice_score: 0.9618 - val_loss: 0.0040 - val_dice_score: 0.9225\n",
      "Epoch 37/200\n",
      "575/575 [==============================] - 303s 526ms/step - loss: 0.0027 - dice_score: 0.9593 - val_loss: 0.0043 - val_dice_score: 0.9372\n",
      "Epoch 38/200\n",
      "575/575 [==============================] - 304s 528ms/step - loss: 0.0028 - dice_score: 0.9607 - val_loss: 0.0044 - val_dice_score: 0.9496\n",
      "Epoch 39/200\n",
      "575/575 [==============================] - 304s 528ms/step - loss: 0.0027 - dice_score: 0.9629 - val_loss: 0.0046 - val_dice_score: 0.9425\n",
      "Epoch 40/200\n",
      "575/575 [==============================] - 323s 561ms/step - loss: 0.0027 - dice_score: 0.9635 - val_loss: 0.0041 - val_dice_score: 0.9366\n",
      "Epoch 41/200\n",
      "575/575 [==============================] - 332s 577ms/step - loss: 0.0028 - dice_score: 0.9574 - val_loss: 0.0040 - val_dice_score: 0.9329\n",
      "Epoch 42/200\n",
      "575/575 [==============================] - 327s 569ms/step - loss: 0.0027 - dice_score: 0.9661 - val_loss: 0.0039 - val_dice_score: 0.9393\n",
      "Epoch 43/200\n",
      "575/575 [==============================] - 319s 554ms/step - loss: 0.0026 - dice_score: 0.9653 - val_loss: 0.0041 - val_dice_score: 0.9297\n",
      "Epoch 44/200\n",
      "176/575 [========>.....................] - ETA: 3:17 - loss: 0.0026 - dice_score: 0.9650"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 200\n",
    "\n",
    "model.fit(\n",
    "    train_data_loader,\n",
    "    validation_data=valid_data_loader,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduceLROnPlat, save_c, csv_logger, make_trainable_callback],\n",
    "    initial_epoch=start_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1234\n",
    "\n",
    "data = train_data_loader.data_getter[index]\n",
    "\n",
    "image_array = data[\"image_array\"]\n",
    "image_array = (image_array + 1) * 127.5\n",
    "image_array = image_array.astype(\"uint8\")\n",
    "\n",
    "mask_array = data[\"mask_array\"]\n",
    "mask_array = (mask_array) * 255\n",
    "mask_array = mask_array.astype(\"uint8\")\n",
    "\n",
    "final_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.RandomRotate90(p=0.5)\n",
    "],\n",
    "    p=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./U_net/vessel_level_1_512_random_org/log.csv') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    dict_from_csv = {field_name:[] for field_name in reader.fieldnames}\n",
    "    print(reader.fieldnames)\n",
    "    for row in reader:\n",
    "        for filedname in reader.fieldnames:\n",
    "            dict_from_csv[filedname].append(float(row[filedname])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(dict_from_csv[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(dict_from_csv[\"dice_score\"])\n",
    "plt.plot(dict_from_csv[\"val_dice_score\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(dict_from_csv[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
